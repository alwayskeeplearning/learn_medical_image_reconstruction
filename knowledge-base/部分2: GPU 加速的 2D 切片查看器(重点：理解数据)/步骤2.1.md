# 步骤 2.1: 理论 - `DataTexture` 用途；精度与格式策略（Float/Half/RGBA8 预窗宽）

## 核心目标

将第一部分在 CPU 上进行的像素处理工作（窗宽窗位调整等），完全迁移到 GPU 上执行，以实现流畅的实时交互。

## 1. 为什么需要 `DataTexture`？

在 Three.js 中，通常使用 `TextureLoader` 来加载 `.jpg` 或 `.png` 等标准图片格式。这个过程包含了浏览器自动的解码、数据转换（通常为 0-255 的 RGBA 整数）和颜色空间处理。

然而，这种方式不适用于医疗影像数据，主要原因如下：

- **原始数据来源**: 我们的数据是 `dicom-parser` 解析出的二进制 `TypedArray` (如 `Int16Array`)，并非图片文件。
- **数据精度**: CT 值的范围（如 -1024 到 3071）远超普通图片 0-255 的范围。强行压缩会导致严重的信息丢失。
- **数据结构**: 我们的数据是单通道的灰度数据，而非图片常见的 RGBA 多通道数据。

`DataTexture` 正是为解决此问题而生。它充当一座桥梁，允许我们将内存中任意格式的原始数据直接上传到 GPU 显存，并在 GPU 上保持其原有的数值精度和结构，绕过了所有图片加载的黑盒操作。

## 2. 精度与格式策略

创建 `DataTexture` 时，需要通过 `format` 和 `type` 两个关键参数告知 GPU 如何解读数据。

- `format`: 定义像素存储的信息类型。
  - `THREE.RedFormat`: 单通道（红色），最适合我们的灰度数据。
  - `THREE.RGBAFormat`: 四通道（红、绿、蓝、透明度）。
- `type`: 定义每个通道的数据类型（精度）。
  - `THREE.ShortType`: 对应 `Int16Array`。
  - `THREE.FloatType`: 对应 `Float32Array`。
  - `THREE.HalfFloatType`: 16 位半浮点数，在性能和精度之间提供了良好的平衡。

### 常见策略对比

| 策略                      | `format`     | `type`             | 数据准备 (CPU端)                        | 优点                                                      | 缺点                                            |
| :------------------------ | :----------- | :----------------- | :-------------------------------------- | :-------------------------------------------------------- | :---------------------------------------------- |
| **策略一：高精度浮点**    | `RedFormat`  | `FloatType`        | 将 `Int16Array` 转换为 `Float32Array`   | **精度最高**，所有计算都在 GPU 中以浮点数完成，完全无损。 | **最耗显存**，每个像素占 32 位。                |
| **策略二：半浮点 (推荐)** | `RedFormat`  | `HalfFloatType`    | 将 `Int16Array` 转换为 `Float32Array`   | **显存/性能与精度的最佳平衡**。                           | 相比 `FloatType` 有微小的精度损失，通常可忽略。 |
| **策略三：整数**          | `RedFormat`  | `ShortType`        | 直接使用 `Int16Array`                   | **最省显存**，数据无需转换。                              | Shader 中需将整数转为浮点数再计算。             |
| **策略四：预处理**        | `RGBAFormat` | `UnsignedByteType` | 在 CPU 端预先应用窗宽窗位，映射到 0-255 | **兼容性最好**，渲染快。                                  | **完全不灵活**，无法在 GPU 端实时调整窗宽窗位。 |

**本教程选择**: 我们将采用**策略二（`HalfFloatType`）**。核心思想是**将原始高精度数据传给 GPU**，然后将窗宽窗位等参数作为 `uniform` 变量传入着色器，让 GPU 实时并行计算。

---

## 问答与深入探讨

### Q1: 为什么要在 CPU 端预先应用 `rescaleSlope` 和 `rescaleIntercept`？全部交给 GPU 不是更好吗？

这是一个非常好的问题，涉及到架构上的权衡。

**回答**:

1.  **架构上的前瞻性**: 我们未来的目标是实现 MIP（最大密度投影）和三维体渲染等高级功能。这些功能需要在着色器中对同一个三维纹理进行大量（几十甚至几百次）的重复采样。

    - **本教程方案 (CPU预处理)**: 加载时，CPU 一次性完成 `pixel * slope + intercept` 的计算。渲染时，GPU 每次采样直接获得最终 CT 值。在 MIP 循环 50 次的场景中，就是 50 次纹理读取。
    - **完全 GPU 方案**: 渲染时，GPU 每次采样后，都需要额外执行一次乘法和加法。在 MIP 循环 50 次的场景中，就变成了 `50次纹理读取 + 50次乘法 + 50次加法`。
      累积的计算开销会变得非常可观。因此，在 CPU 端进行一次性预处理，是一种“用加载时的一次性计算换取后续所有复杂交互的更高性能”的优化策略。

2.  **教学上的关注点分离**: 这样做可以让我们在当前阶段专注于 `DataTexture` 的创建和使用，下一步再专注于 GLSL 和 `uniform` 变量的引入，学习曲线更平滑。

### Q2: 对于一个完整的 DICOM 序列（例如用于 MPR），体数据量很大，在 CPU 侧进行预处理转换成 CT 值会不会导致界面卡顿？

这是一个非常有远见的性能考量。

**回答**:

是的，对于一个包含数百张图像的大序列（例如 `512*512*300`，近 8000 万个体素），在 CPU 主线程中执行这个转换循环**确实会导致界面冻结**，带来糟糕的用户体验。

这里的关键在于区分 **"加载时处理"** 和 **"交互时处理"**:

1.  **加载时处理 (One-time Cost)**: 我们所讨论的 CPU 预处理属于加载时的一次性成本。它发生在用户选择序列、应用准备渲染数据的阶段。
2.  **交互时处理 (Per-frame Cost)**: 指的是用户拖拽、旋转、调整窗位等需要实时响应的操作。我们的架构正是为了保证这一环节的绝对流畅。

**解决方案**:
解决加载时卡顿的最佳实践是使用 **Web Workers**。

专业的处理流程如下：

1.  **主线程**: 响应用户操作，将文件数据发送给 Web Worker，并显示加载动画，UI 保持流畅。
2.  **Web Worker 线程**: 在后台执行所有耗时的计算，包括：
    - 解析所有 DICOM 文件。
    - 堆叠像素数据。
    - 循环应用 `slope` 和 `intercept`，生成一个巨大的 `Float32Array`。
    - 将处理好的数据和元数据回传给主线程。
3.  **主线程**: 接收到数据后，创建 `Data3DTexture` 并上传至 GPU，然后开始渲染。

通过 Web Worker，我们将最重的 CPU 计算任务隔离到后台，从而保证了主线程（UI线程）的流畅响应。

**对于本教程**: 为了简化工程，我们会暂时在主线程进行处理，但在进入三维数据部分时，会再次强调 Web Worker 方案的重要性。
