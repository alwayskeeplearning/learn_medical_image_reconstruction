### 步骤3.4: API: Three.js `Data3DTexture`、WebGL2 能力检测与限制

为了将一个完整的三维数据体高效地上传到 GPU，我们需要使用 `Data3DTexture`。

---

#### 1. 什么是 `Data3DTexture`？

- **从 2D 到 3D 的升级**
  你可以把 `DataTexture` 想象成一张普通的图片。而 `Data3DTexture` 则像是一整本相册或者一叠扑克牌。它是一个单一的纹理对象，但在内部包含了**宽度(width)**、**高度(height)**和**深度(depth)**三个维度的数据。

- **数据结构**
  它接收一个一维的类型化数组（TypedArray，比如 `Float32Array` 或 `Int16Array`），并告诉 GPU：“请把这个长长的一维数组，重新组织成一个 `width * height * depth` 的三维数据块来管理。”

- **优势**
  - **高效存储**: 将整个三维体数据一次性上传到 GPU 显存，避免了管理大量 2D 纹理的开销。
  - **三维采样**: GPU 的纹理单元原生支持对三维纹理进行采样。我们可以在着色器中提供一个三维坐标 `(u, v, w)`（也常叫 `s, t, p`），直接取出对应位置的体素值。这为我们后续实现任意角度的切片（MPR）和光线投射（Volume Rendering）提供了硬件级别的支持。

---

#### 2. WebGL2 的依赖性

这是一个**至关重要**的点：`Data3DTexture` (三维纹理) 是 **WebGL2** 才开始提供的核心功能。WebGL1 是不支持的。这意味着我们的应用程序必须运行在支持 WebGL2 的现代浏览器上。

---

#### 3. 核心 API 讲解

##### a) WebGL2 能力检测

在创建渲染器之前，我们最好先检查一下用户的环境是否支持 WebGL2。

```javascript
import WebGL from 'three/addons/capabilities/WebGL.js';

if (WebGL.isWebGL2Available() === false) {
  // 如果不支持 WebGL2，则进行错误处理
  document.body.appendChild(WebGL.getWebGLErrorMessage());
  throw new Error('您的浏览器或设备不支持 WebGL2，无法运行此应用。');
}

// 如果检查通过，我们就可以安全地创建渲染器了
const renderer = new THREE.WebGLRenderer();
```

- `WebGL.isWebGL2Available()`: 返回一个布尔值，`true` 代表支持。
- `WebGL.getWebGLErrorMessage()`: 如果不支持，这个函数会返回一个友好的提示 DOM 元素，我们可以将它添加到页面上。

##### b) 创建 `Data3DTexture`

```javascript
import * as THREE from 'three';

// 假设 volumeData 是一个包含了所有体素数据的一维 Float32Array
// 假设 volumeSize 是一个包含 {x, y, z} 维度的对象

const texture = new THREE.Data3DTexture(
  volumeData, // 包含所有体素数据的一维类型化数组
  volumeSize.x, // 三维数据体的宽度 (width)
  volumeSize.y, // 三维数据体的高度 (height)
  volumeSize.z, // 三维数据体的深度 (depth)，即切片数量
);

// --- 关键属性设置 ---

// 1. 数据格式 (Format)
texture.format = THREE.RedFormat;

// 2. 数据类型 (Type)
texture.type = THREE.FloatType;

// 3. 纹理过滤 (Filter)
texture.minFilter = THREE.NearestFilter;
texture.magFilter = THREE.NearestFilter;

// 4. Unpack Alignment (内存解包对齐)
texture.unpackAlignment = 1;

// 5. 需要更新
texture.needsUpdate = true;
```

---

#### 4. 硬件限制

`Data3DTexture` 的尺寸受限于用户的 GPU 硬件，主要是**最大纹理尺寸**。

- **正确的 API**: `renderer.capabilities.max3DTextureSize`
- **含义**: 这个属性返回一个整数，代表了当前 GPU 所支持的三维纹理的**最大边长**（宽、高、深任何一个维度都不能超过这个值）。
- **示例**:
  ```javascript
  const max3DTextureSize = renderer.capabilities.max3DTextureSize;
  console.log('当前设备支持的最大3D纹理尺寸为: ' + max3DTextureSize);
  ```

> **注意**: `renderer.capabilities.getMaxAnisotropy()` 返回的是**各向异性过滤**的最大级别，与纹理尺寸无关。

---

#### 5. 深入问答：关于 `unpackAlignment` 的工作原理

**Q1: 如果设置 `format` 为 `RGBA`，`unpackAlignment` 是不是就该设置为4？**

**A1:** 是的，这个理解完全正确。`unpackAlignment` 规定了每行纹理数据在内存中的起始地址必须是多少字节的倍数。当使用 `RGBAFormat` 和 `UnsignedByteType` 时，每个像素占4个字节，所以每行数据的总字节数必然是4的倍数，符合默认值为4的对齐方式。

**Q2: 既然 `RedFormat` + `FloatType` 每个像素也是4个字节，为什么还要把 `unpackAlignment` 设为1？**

**A2:** 这个问题非常核心。对于 `RedFormat` + `FloatType` 的组合，因为每像素4字节，所以每行的总字节数也必然是4的倍数。在这种情况下，设置 `unpackAlignment = 4` 是完全可以的。

**但是，我们依然推荐统一设置为1**，原因是为了**安全和简单**：

1.  **安全（避免踩坑）**: `unpackAlignment` 真正会引发问题的场景是，当**每行数据的总字节数不是默认对齐值（4）的倍数时**。最典型的例子就是 `RedFormat` + `UnsignedByteType`（每像素1字节），如果图像宽度为513，每行就是513字节，不设置 `unpackAlignment=1` 就会导致 WebGL 按4字节对齐去错误地读取数据，导致图像渲染错乱。

2.  **简单（建立统一习惯）**: 我们从程序中处理得到的像素数据（如 `dicom-parser` 解码出的）通常是**紧密打包**的，中间没有任何为对齐而填充的“空字节”。将 `unpackAlignment` 设置为 **1** 就等于在告诉 WebGL：“**你别管什么对齐了，我的数据是紧紧挨在一起的，一个字节挨着一个字节，你照直读就行了。**” 这是一个“万金油”设置，无论 `format` 和 `type` 如何组合，它永远是正确的，能避免我们每次都要去心算字节对齐问题。

**总结表格**:

| Format       | Type               | 每像素字节数 | 行字节数 (width=513) | `unpackAlignment` 设置                       |
| :----------- | :----------------- | :----------- | :------------------- | :------------------------------------------- |
| `RedFormat`  | `UnsignedByteType` | 1            | 513                  | **必须设为1** (否则默认按4对齐，读取会错位)  |
| `RedFormat`  | `FloatType`        | 4            | 2052 (是4的倍数)     | **设为4或1都可以** (推荐1，作为通用安全习惯) |
| `RGBAFormat` | `UnsignedByteType` | 4            | 2052 (是4的倍数)     | **设为4或1都可以** (推荐1，作为通用安全习惯) |
