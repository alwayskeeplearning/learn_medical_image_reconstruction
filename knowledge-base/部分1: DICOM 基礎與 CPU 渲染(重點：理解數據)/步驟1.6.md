# 步骤1.6: 实践 - CPU 端实现 WW/WL 并在 Canvas2D 显示

## 实践目标

将前面所有步骤学习的理论知识融会贯通，创建一个网页，当用户选择DICOM文件后，程序能自动执行完整的CPU端显示链路（包括Rescale变换和窗宽窗位映射），并将最终的灰度图像成功渲染到一个`<canvas>`元素上。

## 核心实现解读

这次实践的核心是 `renderImage` 函数，它精确地执行了我们之前讨论的所有理论步骤，将一维的原始像素数据流，转化为二维的、可视化的图像。

**关键渲染流程:**

1.  **准备工作**:

    - 根据DICOM元数据中的 `width` 和 `height` 设置 `<canvas>` 的尺寸。
    - 使用 `ctx.createImageData()` 创建一个尺寸正确、内容空白的 `ImageData` 容器。
    - 根据元数据中的 `windowCenter` 和 `windowWidth` 计算出用于筛选像素值的 `lower` (观察下限) 和 `upper` (观察上限)。

2.  **核心像素循环**:

    - 我们遍历`pixelData`数组（通常是 `Int16Array` 或 `Uint16Array`）中的**每一个**像素值。
    - **Rescale变换**: `realValue = storedValue * rescaleSlope + rescaleIntercept`。将存储的整数值转换为有物理意义的真实值（如HU值）。这是显示链路的**第一步**。
    - **窗宽窗位映射**: 对上一步得到的`realValue`进行判断。
      - 如果值在 `[lower, upper]` 区间之外，直接映射为纯黑(0)或纯白(255)。
      - 如果值在区间之内，则使用线性公式 `grayValue = ((realValue - lower) / windowWidth) * 255` 将其映射到 `0-255` 的灰度范围。
    - **处理负片(`MONOCHROME1`)**: 检查 `photometricInterpretation` 标签，如果需要，则执行 `grayValue = 255 - grayValue` 进行反色处理。
    - **写入RGBA**: 将最终计算出的 `grayValue` **同时**写入 `ImageData` 数组对应像素的 R, G, B 三个通道，并将 Alpha 通道设为 255 (完全不透明)。
    - 通过 `pixelIndex += 4` 正确移至下一个像素的起始位置。

3.  **最终绘制**:
    - 当循环结束，`imageData` 对象已被所有像素的颜色数据填满。
    - 调用 `ctx.putImageData(imageData, 0, 0)` 指令，将我们精心计算出的所有像素一次性“印”到 `<canvas>` 画布上，完成渲染。

## 成果

成功地在浏览器中渲染出了DICOM图像。这标志着我们已经完全打通了从一个二进制DICOM文件，到肉眼可见、有意义的医学影像的完整CPU处理链路，是整个课程中的一个巨大里程碑。
